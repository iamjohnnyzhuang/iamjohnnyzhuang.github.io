---
layout: post
title: Spark 键值对算子小结
categories: [spark]
---



## 前言

Spark对数据的操作核心也是围绕着MapReduce。对于这类操作，我们最常做的就是类似WordCount中将一个个单词弄成(Word,1)这样的键值对，然后基于键值对操作。

Spark无论是对RDD还是DStream都提供了丰富的键值对操作。本文主要总结下我个人在工作中常用的几个操作以及对其的一些理解。包括如下：

* **reduceByKey**
* **groupByKey**
* combineByKey
* aggregateByKey


其中我最常用的莫属于reduceByKey、groupByKey。这篇文件主要围绕这两个操作展开，对于其他的几个操作目前在工作中较少用到，因此先不展开了后续再补上。




## 准备数据

```scala
var rdd = sc.makeRDD(Array(("A",2),("C",2),("C",3),("E",1)))
```

该数据模拟简单的WordCount。

Key表示某个字符，对应的Value则是其出现的次数。




## 实验操作

### 1. reduceByKey

该操作是最常见的操作。通过该操作可以将Pair中Key相同的聚合起来，并且通过一个指定的聚合函数来聚合他们。最后会返回一系列独一无二的Key、Value值。典型的WordCount就是基于此。

``` scala
scala> rdd.reduceByKey(_ + _).collect()
res1: Array[(String, Int)] = Array((A,2), (E,1), (C,5))
```

**注意：**

该操作是十分常见的操作的，且是map side的。因此应该优先于使用该函数而非下文介绍的groupByKey。

> 什么是map side?
>
> 所谓的map-side预聚合，说的是在每个节点本地对相同的key进行一次聚合操作，类似于MapReduce中的本地combiner。map-side预聚合之后，每个节点本地就只会有一条相同的key，因为多条相同的key都被聚合起来了。其他节点在拉取所有节点上的相同key时，就会大大减少需要拉取的数据数量，从而也就减少了磁盘IO以及网络传输开销。通常来说，在可能的情况下，建议使用reduceByKey或者aggregateByKey算子来替代掉groupByKey算子。因为reduceByKey和aggregateByKey算子都会使用用户自定义的函数对每个节点本地的相同key进行预聚合。而groupByKey算子是不会进行预聚合的，全量的数据会在集群的各个节点之间分发和传输，性能相对来说比较差。
>
> —— 《Spark性能优化指南——基础篇》



### 2. groupByKey

该操作也是常用操作之一。顾名思义，该操作可以将Key相同的值聚合在一起形成一个组。

``` scala
scala> rdd.groupByKey().collect()
res3: Array[(String, Iterable[Int])] = Array((A,CompactBuffer(2)), (E,CompactBuffer(1)), (C,CompactBuffer(2, 3)))
```

与reduceByKey不同，该操作无需指定聚合函数。因此仅仅只是做了数据的聚合。

关于该操作值得一提的是map side的特性，上文已经提到。

``` scala
  /**
   * Group the values for each key in the RDD into a single sequence. Hash-partitions the
   * resulting RDD with the existing partitioner/parallelism level.
   *
   * @note If you are grouping in order to perform an aggregation (such as a sum or average) over
   * each key, using `JavaPairRDD.reduceByKey` or `JavaPairRDD.combineByKey`
   * will provide much better performance.
   */
  def groupByKey(): JavaPairRDD[K, JIterable[V]] =
    fromRDD(groupByResultToJava(rdd.groupByKey()))
```

在更深层次中可以看到：

``` scala
  /**
   * Group the values for each key in the RDD into a single sequence. Allows controlling the
   * partitioning of the resulting key-value pair RDD by passing a Partitioner.
   * The ordering of elements within each group is not guaranteed, and may even differ
   * each time the resulting RDD is evaluated.
   *
   * @note This operation may be very expensive. If you are grouping in order to perform an
   * aggregation (such as a sum or average) over each key, using `PairRDDFunctions.aggregateByKey`
   * or `PairRDDFunctions.reduceByKey` will provide much better performance.
   *
   * @note As currently implemented, groupByKey must be able to hold all the key-value pairs for any
   * key in memory. If a key has too many values, it can result in an [[OutOfMemoryError]].
   */
  def groupByKey(partitioner: Partitioner): RDD[(K, Iterable[V])] = self.withScope {
    // groupByKey shouldn't use map side combine because map side combine does not
    // reduce the amount of data shuffled and requires all map side data be inserted
    // into a hash table, leading to more objects in the old gen.
    val createCombiner = (v: V) => CompactBuffer(v)
    val mergeValue = (buf: CompactBuffer[V], v: V) => buf += v
    val mergeCombiners = (c1: CompactBuffer[V], c2: CompactBuffer[V]) => c1 ++= c2
    val bufs = combineByKeyWithClassTag[CompactBuffer[V]](
      createCombiner, mergeValue, mergeCombiners, partitioner, mapSideCombine = false)
    bufs.asInstanceOf[RDD[(K, Iterable[V])]]
  }
```

从上可以看出来，官方对该方法的评价是：该方法非常昂贵。在Spark程序中，我们应该尽量减少该函数的使用，使用reduceByKey、aggregateByKey或者combineByKey等算子来代替。

从源码也可以知道，groupByKey底层还是使用combineByKey来实现的。**同时，指定的mapSideCombine = false。表示这不是一个mapSide预聚合的函数。为啥groupByKey不做预聚合呢？源码也给出了很详细的说明：**

> ```
> // groupByKey shouldn't use map side combine because map side combine does not
> // reduce the amount of data shuffled and requires all map side data be inserted
> // into a hash table, leading to more objects in the old gen.
> ```



#### 那么，Spark Streaming中的groupByKey也一样吗？

但是当我今天看了Spark Streaming中DStream的GroupByKey源码时才发现，在Streaming中的DStream GroupByKey却是map side的。

``` scala
  /**
   * Return a new DStream by applying `groupByKey` on each RDD. The supplied
   * org.apache.spark.Partitioner is used to control the partitioning of each RDD.
   */
  def groupByKey(partitioner: Partitioner): DStream[(K, Iterable[V])] = ssc.withScope {
    val createCombiner = (v: V) => ArrayBuffer[V](v)
    val mergeValue = (c: ArrayBuffer[V], v: V) => (c += v)
    val mergeCombiner = (c1: ArrayBuffer[V], c2: ArrayBuffer[V]) => (c1 ++ c2)
    combineByKey(createCombiner, mergeValue, mergeCombiner, partitioner)
      .asInstanceOf[DStream[(K, Iterable[V])]]
  }
```

combineByKey 源码：

``` scala
  /**
   * Combine elements of each key in DStream's RDDs using custom functions. This is similar to the
   * combineByKey for RDDs. Please refer to combineByKey in
   * org.apache.spark.rdd.PairRDDFunctions in the Spark core documentation for more information.
   */
  def combineByKey[C: ClassTag](
      createCombiner: V => C,
      mergeValue: (C, V) => C,
      mergeCombiner: (C, C) => C,
      partitioner: Partitioner,
      mapSideCombine: Boolean = true): DStream[(K, C)] = ssc.withScope {
    val cleanedCreateCombiner = sparkContext.clean(createCombiner)
    val cleanedMergeValue = sparkContext.clean(mergeValue)
    val cleanedMergeCombiner = sparkContext.clean(mergeCombiner)
    new ShuffledDStream[K, V, C](
      self,
      cleanedCreateCombiner,
      cleanedMergeValue,
      cleanedMergeCombiner,
      partitioner,
      mapSideCombine)
  }
```

可以看到combineByKey默认的mapSideCombine是True。所以groupByKey也默认是使用预聚合，且也不再有spark源码上那些关于性能警告的注释了。

看到这个问题，我也上google进行了一番查询，但是几乎关于此的讨论也微乎其微，且目前的项目中关于Streaming中使用groupByKey/groupByKeyAndWindow都还没出现任何性能瓶颈，姑且认为DStream的groupByKey不再存在那个性能问题吧，后续再学习学习。



#### 怎样优化groupByKey

如果很不幸确实需要用到groupByKey这个特性怎么办呢？

**我们可以巧用 mapValues + reduceByKey 来替代groupByKey。**

假如我们的需要是要对key一样的值聚合起来然后求平均值，可以直接先用mapValues将value映射成一个Pair(总个数,当前总值)，然后使用reduceByKey聚合合并最后得到一个个Pair即可求出。



## 写在最后

掌握了reduceByKey以及groupByKey基本能应付工作中大部分需求了，可是对于一些复杂的可能还得需要自己调用底层函数——combineByKey。

后续对于combineByKey、aggregateByKey的学习还得继续！