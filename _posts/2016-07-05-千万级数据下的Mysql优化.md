---
layout: post
title: 千万级数据下的Mysql优化
categories: [database]
---

# 前言
平时在写一些小web系统时，我们总会对mysql不以为然。然而**真正的系统易用应该讲数据量展望拓展到千万级别来考虑。**因此，今天下午实在是无聊的慌，自己随手搭建一个千万级的数据库，然后对数据库进行一些简单的CRUD来看看大数据情况下的CRUD效率。

结果发现，曾经简单的操作，在数据量大的时候还是会造成操作效率低下的。因此先写下这篇文章，日后不断更新纪录一下自己工作学习到的Mysql优化技巧。

----

# 搭建千万级数据库
首先，需要一个测试环境。一开始想到的是写一个SImple JDBC程序然进行简单的数据INSERT。结果发现单线程情况下，每次INSERT了一百多万条的时候效率就变得非常的低下。但是程序也没报OUT MEMORY之类的异常。初步判断应该是单一线程不断的疯狂创建PrepareStatement对象CG没来得及清理造成内存逐渐被吃紧的原因。

后来改进了一下，用多线程的机制。创建十个进程，每个负责一万条数据的插入。这效率一下子提升了好几倍。然而好景不长，很快的Java程序报错：OUT  MEMORY。内存溢出了，CG没来得及清理。

这可把我给急的了。插入的太快内存CPU吃紧，插入的太慢又失去了创建测试环境“快”的初衷。后来想了下，既然是要批量插入数据，那么不是可以简单的写一段**数据库存储过程**吗？

于是，先建立一张测试表，就叫**goods表**吧。先写sql语句创建表：
{% highlight sql%}
CREATE TABLE goods (
id serial,
NAME VARCHAR (10),
price DOUBLE
) ENGINE = MYISAM DEFAULT CHARACTER
SET = utf8 COLLATE = utf8_general_ci AUTO_INCREMENT = 1 ROW_FORMAT = COMPACT;
{% endhighlight %}

接下来根据表结构写一段存储过程让数据库自行重复插入数据：

{% highlight sql %}
begin
declare i int default 0 ;
dd:loop 
insert  into goods values
(null,'商品1',20),
(null,'商品2',18),
(null,'商品3',16),
(null,'商品4',4),
(null,'商品5',13),
(null,'商品6',1),
(null,'商品7',11),
(null,'商品8',12),
(null,'商品9',13),
(null,'商品0',12);
  commit;
set i = i+10 ;
   if  i = 10000000 then leave dd;
  end if;
 end loop dd ;
end
{% endhighlight %}

写完后运行一下，ok千万级别的数据库马上就插入进去了。

----

# 再谈数据库优化
既然有了数据现在开始进入数据库优化环节。


## 一、分页查询的优化
首先我们常常涉及到的CRUD操作莫过于分页操作。
对于普通的分页操作我们常常是这样子

{% highlight sql %}
select * from goods limit 100,1000;  
{% endhighlight %}

这样当然没有任何的问题，但是当我们的数据量非常大，假如我要查看的是第八百万条数据呢？对应的sql语句为：
{% highlight sql %}
select  * from goods limit 8000000,1000;
{% endhighlight %}
Mysql执行时间为 1.5秒左右。那么我们可以做一些什么优化吗？

上述的sql语句造成的效率低下原因不外乎：
> 大的分页偏移量会增加使用的数据，MySQL会将大量最终不会使用的数据加载到内存中。就算我们假设大部分网站的用户只访问前几页数据，但少量的大的分页偏移量的请求也会对整个系统造成危害

那么我要怎样来优化呢？**如果我们的id为自增的。也就是说每一条记录的id为上一条id + 1那么，分页查找我们可以使用id进行范围查找替代传统的limit。**

例如上述的sql语句可以代替为：
{% highlight sql %}
select * from goods where id  > 8000000 limit 1000;
{% endhighlight %}

上述sql的到同样的执行结果，执行时间却只有0.04秒。提升了40倍左右。

**结论：对应于自增id的表，如果数据量非常大的分页查找，可以观察id的分布规律计算出其id的范围通过范围查找来实现分页效果。**


## 二、索引优化
谈到数据库效率，大部分人的第一想法应该就是建立索引。没错，正确的建立索引可以很好的提升效率。

关于索引，这是一个很大的话题我就不打算在这篇文章概括起来了。推荐一篇[美团技术博客关于索引的文章][1]。这篇文章很好的概述了索引的使用场景。主要要注意最左前缀匹配原则，并且将索引建立在区分度高的列。区分度的计算公式为：
> count(distinct col)/count(*)*
> 因此像我的模拟数据中即使建立了索引效率也提升不了多少，因为区分度非常的低。

**结论：索引很重要，也是一个大话题。推荐看看那篇美团技术博客的文章可以学习到很多。**

[1]: http://tech.meituan.com/mysql-index.html